{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceaa354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99bae003",
   "metadata": {},
   "source": [
    "## YOLO model for Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99450d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 8 persons, 25 cars, 8 motorcycles, 4 buss, 5 trucks, 343.9ms\n",
      "Speed: 3.5ms preprocess, 343.9ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "from ultralytics import YOLO\n",
    "model=YOLO(\"yolov8s.pt\")\n",
    "\n",
    "\n",
    "# Load the local image\n",
    "#image_path = r\"C:\\Users\\koti0\\OneDrive\\Desktop\\obj_detection\\000000039769.jpg\"\n",
    "#image = cv2.imread(image_path)\n",
    "\n",
    "url= \"https://assets.bwbx.io/images/users/iqjWHBFdfxIU/in4fenEak98Q/v0/-1x-1.jpg\"\n",
    "\n",
    "# Open the URL and read the image data\n",
    "req = urllib.request.urlopen(url)\n",
    "arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
    "\n",
    "# Decode the image data to a cv2 image\n",
    "image = cv2.imdecode(arr, -1)\n",
    "\n",
    "results=model(image)\n",
    "boxes=results[0].boxes.data\n",
    "class_names=results[0].names\n",
    "\n",
    "# Retrieve boxes and class names from the YOLO results\n",
    "boxes = results[0].boxes.data\n",
    "class_names = results[0].names\n",
    "\n",
    "# Draw bounding boxes on the image\n",
    "for box in boxes:\n",
    "    x1, y1, x2, y2, conf, class_id = box\n",
    "    class_name = class_names[int(class_id)]\n",
    "    color = (0, 255, 0)  # Green color for bounding boxes\n",
    "    thickness = 2  # Thickness of the bounding box lines\n",
    "    cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), color, thickness)\n",
    "    cv2.putText(image, class_name, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n",
    "\n",
    "# Display the image with bounding boxes\n",
    "cv2.imshow(\"Object Detection\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7d0541",
   "metadata": {},
   "source": [
    "## YOLO Model for Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e1d29f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 1 person, 9 cars, 2 trains, 5 trucks, 309.9ms\n",
      "Speed: 3.0ms preprocess, 309.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 7 cars, 1 bus, 1 train, 3 trucks, 253.7ms\n",
      "Speed: 3.0ms preprocess, 253.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 7 cars, 3 trucks, 267.5ms\n",
      "Speed: 3.5ms preprocess, 267.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 1 train, 3 trucks, 276.6ms\n",
      "Speed: 3.5ms preprocess, 276.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 8 cars, 1 train, 5 trucks, 213.9ms\n",
      "Speed: 3.0ms preprocess, 213.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 3 trucks, 218.5ms\n",
      "Speed: 2.5ms preprocess, 218.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 7 cars, 5 trucks, 204.3ms\n",
      "Speed: 2.0ms preprocess, 204.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 1 train, 3 trucks, 253.2ms\n",
      "Speed: 2.0ms preprocess, 253.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 4 trucks, 232.7ms\n",
      "Speed: 2.0ms preprocess, 232.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 5 trucks, 263.6ms\n",
      "Speed: 4.0ms preprocess, 263.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 4 cars, 6 trucks, 227.7ms\n",
      "Speed: 3.0ms preprocess, 227.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 5 trucks, 256.9ms\n",
      "Speed: 2.0ms preprocess, 256.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 6 trucks, 235.7ms\n",
      "Speed: 3.5ms preprocess, 235.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 7 trucks, 269.7ms\n",
      "Speed: 4.0ms preprocess, 269.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 1 train, 6 trucks, 234.4ms\n",
      "Speed: 3.1ms preprocess, 234.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 1 train, 8 trucks, 258.2ms\n",
      "Speed: 2.0ms preprocess, 258.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 1 bus, 1 train, 7 trucks, 254.7ms\n",
      "Speed: 3.0ms preprocess, 254.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 8 cars, 1 bus, 1 train, 5 trucks, 270.4ms\n",
      "Speed: 3.0ms preprocess, 270.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 6 cars, 1 bus, 4 trucks, 272.5ms\n",
      "Speed: 5.0ms preprocess, 272.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 1 bus, 5 trucks, 257.2ms\n",
      "Speed: 2.0ms preprocess, 257.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 1 bus, 6 trucks, 232.5ms\n",
      "Speed: 3.0ms preprocess, 232.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 1 bus, 6 trucks, 264.5ms\n",
      "Speed: 4.0ms preprocess, 264.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 2 buss, 6 trucks, 250.7ms\n",
      "Speed: 4.5ms preprocess, 250.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 8 cars, 1 bus, 7 trucks, 266.7ms\n",
      "Speed: 3.5ms preprocess, 266.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 1 bus, 2 trucks, 243.5ms\n",
      "Speed: 4.5ms preprocess, 243.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 2 buss, 3 trucks, 243.8ms\n",
      "Speed: 3.0ms preprocess, 243.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 8 cars, 2 buss, 3 trucks, 255.8ms\n",
      "Speed: 3.5ms preprocess, 255.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 8 cars, 2 buss, 2 trucks, 255.3ms\n",
      "Speed: 3.0ms preprocess, 255.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 7 cars, 2 buss, 4 trucks, 229.3ms\n",
      "Speed: 2.0ms preprocess, 229.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 8 cars, 2 buss, 3 trucks, 235.8ms\n",
      "Speed: 3.0ms preprocess, 235.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 8 cars, 2 buss, 6 trucks, 276.6ms\n",
      "Speed: 2.0ms preprocess, 276.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 9 cars, 2 buss, 5 trucks, 260.9ms\n",
      "Speed: 5.0ms preprocess, 260.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 8 cars, 2 buss, 5 trucks, 237.3ms\n",
      "Speed: 3.0ms preprocess, 237.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 9 cars, 2 buss, 7 trucks, 244.5ms\n",
      "Speed: 2.8ms preprocess, 244.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 10 cars, 2 buss, 4 trucks, 271.1ms\n",
      "Speed: 4.0ms preprocess, 271.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 9 cars, 2 buss, 1 truck, 260.7ms\n",
      "Speed: 2.0ms preprocess, 260.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 8 cars, 2 buss, 2 trucks, 254.8ms\n",
      "Speed: 2.0ms preprocess, 254.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 10 cars, 2 buss, 1 train, 4 trucks, 240.4ms\n",
      "Speed: 2.5ms preprocess, 240.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 8 cars, 2 buss, 1 train, 2 trucks, 247.4ms\n",
      "Speed: 3.0ms preprocess, 247.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 8 cars, 2 buss, 2 trucks, 290.7ms\n",
      "Speed: 2.0ms preprocess, 290.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 9 cars, 2 buss, 3 trucks, 253.9ms\n",
      "Speed: 3.5ms preprocess, 253.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 2 buss, 5 trucks, 228.9ms\n",
      "Speed: 3.0ms preprocess, 228.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 2 buss, 3 trucks, 276.1ms\n",
      "Speed: 3.0ms preprocess, 276.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 2 buss, 6 trucks, 251.4ms\n",
      "Speed: 2.0ms preprocess, 251.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 1 bus, 4 trucks, 284.1ms\n",
      "Speed: 3.0ms preprocess, 284.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 2 buss, 5 trucks, 250.4ms\n",
      "Speed: 2.3ms preprocess, 250.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 2 buss, 5 trucks, 238.1ms\n",
      "Speed: 2.4ms preprocess, 238.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 2 buss, 5 trucks, 261.9ms\n",
      "Speed: 3.0ms preprocess, 261.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 2 buss, 5 trucks, 271.9ms\n",
      "Speed: 3.0ms preprocess, 271.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 2 buss, 8 trucks, 235.1ms\n",
      "Speed: 2.0ms preprocess, 235.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 2 buss, 5 trucks, 254.2ms\n",
      "Speed: 3.0ms preprocess, 254.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 2 buss, 6 trucks, 264.2ms\n",
      "Speed: 2.0ms preprocess, 264.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 1 bus, 1 train, 3 trucks, 230.1ms\n",
      "Speed: 2.0ms preprocess, 230.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 1 train, 4 trucks, 262.1ms\n",
      "Speed: 2.1ms preprocess, 262.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 3 trucks, 271.9ms\n",
      "Speed: 3.8ms preprocess, 271.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 4 trucks, 197.4ms\n",
      "Speed: 2.5ms preprocess, 197.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 1 train, 2 trucks, 240.2ms\n",
      "Speed: 2.0ms preprocess, 240.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 5 cars, 1 train, 2 trucks, 205.3ms\n",
      "Speed: 2.0ms preprocess, 205.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 1 train, 4 trucks, 212.4ms\n",
      "Speed: 3.0ms preprocess, 212.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 1 train, 3 trucks, 213.8ms\n",
      "Speed: 2.5ms preprocess, 213.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 2 trucks, 215.9ms\n",
      "Speed: 2.0ms preprocess, 215.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 1 train, 3 trucks, 210.2ms\n",
      "Speed: 3.0ms preprocess, 210.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 1 train, 1 truck, 210.1ms\n",
      "Speed: 2.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 3 cars, 1 motorcycle, 1 train, 4 trucks, 210.2ms\n",
      "Speed: 2.0ms preprocess, 210.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 1 motorcycle, 1 train, 5 trucks, 200.7ms\n",
      "Speed: 2.1ms preprocess, 200.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 3 cars, 1 motorcycle, 1 train, 2 trucks, 215.8ms\n",
      "Speed: 2.5ms preprocess, 215.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 1 train, 3 trucks, 209.5ms\n",
      "Speed: 2.5ms preprocess, 209.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 2 persons, 4 cars, 1 train, 2 trucks, 221.3ms\n",
      "Speed: 2.0ms preprocess, 221.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 6 cars, 1 train, 2 trucks, 209.5ms\n",
      "Speed: 1.5ms preprocess, 209.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 1 train, 4 trucks, 223.3ms\n",
      "Speed: 3.0ms preprocess, 223.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 1 train, 2 trucks, 255.4ms\n",
      "Speed: 3.0ms preprocess, 255.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 6 cars, 1 train, 1 truck, 252.1ms\n",
      "Speed: 2.0ms preprocess, 252.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 1 train, 4 trucks, 202.6ms\n",
      "Speed: 3.0ms preprocess, 202.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 1 train, 4 trucks, 208.4ms\n",
      "Speed: 2.5ms preprocess, 208.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 1 train, 6 trucks, 206.6ms\n",
      "Speed: 2.0ms preprocess, 206.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 2 persons, 4 cars, 1 train, 7 trucks, 210.7ms\n",
      "Speed: 2.0ms preprocess, 210.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 7 trucks, 225.6ms\n",
      "Speed: 2.0ms preprocess, 225.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 4 trucks, 187.5ms\n",
      "Speed: 3.5ms preprocess, 187.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 5 cars, 5 trucks, 199.2ms\n",
      "Speed: 2.0ms preprocess, 199.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 7 trucks, 188.7ms\n",
      "Speed: 2.0ms preprocess, 188.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 5 cars, 6 trucks, 209.7ms\n",
      "Speed: 2.0ms preprocess, 209.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 4 cars, 4 trucks, 197.6ms\n",
      "Speed: 2.0ms preprocess, 197.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 5 cars, 3 trucks, 174.3ms\n",
      "Speed: 3.0ms preprocess, 174.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 3 cars, 3 trucks, 205.4ms\n",
      "Speed: 2.0ms preprocess, 205.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 3 cars, 4 trucks, 202.4ms\n",
      "Speed: 3.5ms preprocess, 202.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 2 cars, 4 trucks, 208.8ms\n",
      "Speed: 2.0ms preprocess, 208.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 3 cars, 4 trucks, 215.2ms\n",
      "Speed: 2.0ms preprocess, 215.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 3 cars, 5 trucks, 208.3ms\n",
      "Speed: 2.0ms preprocess, 208.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 6 trucks, 196.1ms\n",
      "Speed: 2.1ms preprocess, 196.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 6 trucks, 218.0ms\n",
      "Speed: 2.4ms preprocess, 218.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 3 cars, 4 trucks, 187.3ms\n",
      "Speed: 2.0ms preprocess, 187.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 3 cars, 5 trucks, 183.2ms\n",
      "Speed: 2.0ms preprocess, 183.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 3 trucks, 223.0ms\n",
      "Speed: 2.0ms preprocess, 223.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 3 trucks, 191.4ms\n",
      "Speed: 3.0ms preprocess, 191.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 3 trucks, 196.4ms\n",
      "Speed: 2.5ms preprocess, 196.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 6 trucks, 213.8ms\n",
      "Speed: 2.5ms preprocess, 213.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 3 cars, 4 trucks, 218.9ms\n",
      "Speed: 3.0ms preprocess, 218.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 5 trucks, 211.3ms\n",
      "Speed: 3.0ms preprocess, 211.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 1 bus, 3 trucks, 1 traffic light, 215.3ms\n",
      "Speed: 3.0ms preprocess, 215.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 1 bus, 4 trucks, 217.9ms\n",
      "Speed: 2.0ms preprocess, 217.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 5 cars, 1 bus, 5 trucks, 160.2ms\n",
      "Speed: 3.0ms preprocess, 160.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 6 cars, 1 bus, 2 trucks, 197.6ms\n",
      "Speed: 2.0ms preprocess, 197.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 6 cars, 1 bus, 2 trucks, 1 traffic light, 211.3ms\n",
      "Speed: 2.5ms preprocess, 211.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 6 cars, 1 bus, 2 trucks, 193.0ms\n",
      "Speed: 1.5ms preprocess, 193.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 4 trucks, 197.3ms\n",
      "Speed: 4.0ms preprocess, 197.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 4 trucks, 185.3ms\n",
      "Speed: 4.5ms preprocess, 185.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 4 trucks, 207.9ms\n",
      "Speed: 2.5ms preprocess, 207.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 5 trucks, 195.3ms\n",
      "Speed: 3.0ms preprocess, 195.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 4 trucks, 206.8ms\n",
      "Speed: 2.0ms preprocess, 206.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 6 cars, 6 trucks, 202.9ms\n",
      "Speed: 2.0ms preprocess, 202.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 7 trucks, 235.4ms\n",
      "Speed: 2.0ms preprocess, 235.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 4 trucks, 195.5ms\n",
      "Speed: 2.0ms preprocess, 195.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 4 trucks, 212.3ms\n",
      "Speed: 2.0ms preprocess, 212.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 5 cars, 7 trucks, 207.4ms\n",
      "Speed: 3.0ms preprocess, 207.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 4 cars, 6 trucks, 197.4ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.1ms preprocess, 197.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 2 cars, 7 trucks, 199.4ms\n",
      "Speed: 1.9ms preprocess, 199.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 5 cars, 4 trucks, 194.6ms\n",
      "Speed: 2.0ms preprocess, 194.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 5 cars, 1 truck, 185.3ms\n",
      "Speed: 1.0ms preprocess, 185.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 4 cars, 2 trucks, 202.1ms\n",
      "Speed: 2.5ms preprocess, 202.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 2 persons, 4 cars, 4 trucks, 179.6ms\n",
      "Speed: 2.5ms preprocess, 179.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 3 cars, 5 trucks, 205.9ms\n",
      "Speed: 2.0ms preprocess, 205.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 2 cars, 5 trucks, 212.1ms\n",
      "Speed: 3.0ms preprocess, 212.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 1 car, 6 trucks, 232.6ms\n",
      "Speed: 3.5ms preprocess, 232.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 1 car, 7 trucks, 217.1ms\n",
      "Speed: 2.0ms preprocess, 217.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 4 cars, 4 trucks, 1 traffic light, 197.6ms\n",
      "Speed: 2.0ms preprocess, 197.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 4 cars, 4 trucks, 217.5ms\n",
      "Speed: 2.0ms preprocess, 217.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 5 cars, 4 trucks, 1 traffic light, 201.3ms\n",
      "Speed: 2.5ms preprocess, 201.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 4 cars, 5 trucks, 1 traffic light, 202.3ms\n",
      "Speed: 2.0ms preprocess, 202.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 6 cars, 6 trucks, 217.0ms\n",
      "Speed: 2.5ms preprocess, 217.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 5 cars, 3 trucks, 199.2ms\n",
      "Speed: 2.0ms preprocess, 199.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "# Open a video file for input (replace 'input_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\koti0\\Downloads\\video (2160p).mp4\")\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.resize(frame, (400,600))\n",
    "\n",
    "    # Perform object detection on the frame\n",
    "    results = model(frame)\n",
    "\n",
    "    # Retrieve boxes and class names from the YOLO results\n",
    "    boxes = results[0].boxes.data\n",
    "    class_names = results[0].names\n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2, conf, class_id = box\n",
    "        class_name = class_names[int(class_id)]\n",
    "        color = (0, 255, 0)  # Green color for bounding boxes\n",
    "        thickness = 2  # Thickness of the bounding box lines\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, thickness)\n",
    "        cv2.putText(frame, class_name, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "    \n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103c44e9",
   "metadata": {},
   "source": [
    "## DETR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "417f8b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at C:\\Users\\koti0\\OneDrive\\Desktop\\obj_detection\\detr and are newly initialized: ['model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "# Load the DETR processor and model\n",
    "processor = DetrImageProcessor.from_pretrained(r\"C:\\Users\\koti0\\OneDrive\\Desktop\\obj_detection\\detr\")\n",
    "model = DetrForObjectDetection.from_pretrained(r\"C:\\Users\\koti0\\OneDrive\\Desktop\\obj_detection\\detr\")\n",
    "\n",
    "# Load the local image\n",
    "#image_path = r\"C:\\Users\\koti0\\OneDrive\\Desktop\\obj_detection\\000000039769.jpg\"\n",
    "#image = cv2.imread(image_path)\n",
    "\n",
    "url= \"https://assets.bwbx.io/images/users/iqjWHBFdfxIU/in4fenEak98Q/v0/-1x-1.jpg\"\n",
    "\n",
    "# Open the URL and read the image data\n",
    "req = urllib.request.urlopen(url)\n",
    "arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
    "\n",
    "# Decode the image data to a cv2 image\n",
    "image = cv2.imdecode(arr, -1)\n",
    "image = cv2.resize(image, (1250,800))\n",
    "\n",
    "\n",
    "# Process the image using the processor\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Convert outputs (bounding boxes and class logits) to COCO API format\n",
    "# Let's only keep detections with score > 0.9\n",
    "target_sizes = torch.tensor([image.shape[:2:]])\n",
    "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.3)[0]\n",
    "\n",
    "# Convert PIL image to NumPy array for OpenCV\n",
    "image_np = np.array(image)\n",
    "#image_cv2 = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
    "image_cv2=image.copy()\n",
    "\n",
    "# Define the font for labels\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.5\n",
    "font_thickness = 1\n",
    "font_color = (255, 255, 255)  # White color\n",
    "\n",
    "# Iterate over the results and draw bounding boxes and labels using OpenCV\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "\n",
    "    # Draw the bounding box\n",
    "    box = [int(b) for b in box]  # Convert to integers for drawing\n",
    "    cv2.rectangle(image_cv2, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), 1)  # Red rectangle\n",
    "\n",
    "    # Draw the label\n",
    "    label_text = f\"{model.config.id2label[label.item()]}: {round(score.item(), 3)}\"\n",
    "    label_size = cv2.getTextSize(label_text, font, font_scale, font_thickness)[0]\n",
    "    label_bottom_left = (box[0], box[1] - 5)  # Adjust label position\n",
    "    label_top_right = (label_bottom_left[0] + label_size[0], label_bottom_left[1] - label_size[1])\n",
    "    cv2.rectangle(image_cv2, label_bottom_left, label_top_right, (0, 0, 255), cv2.FILLED)  # Red filled rectangle\n",
    "    cv2.putText(image_cv2, label_text, (box[0], box[1] - 5), font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n",
    "\n",
    "# Display the image with OpenCV\n",
    "cv2.imshow('Image with Bounding Boxes and Labels', image_cv2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the image using OpenCV\n",
    "cv2.imwrite(\"saved_image.jpg\", image_cv2)\n",
    "print(\"Image saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a9655a",
   "metadata": {},
   "source": [
    "## DETR Model for Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e2292d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a video file for input (replace 'input_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\koti0\\Downloads\\video (2160p).mp4\")\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame (optional, adjust as needed)\n",
    "    frame = cv2.resize(frame, (1250, 800))\n",
    "\n",
    "    # Convert the frame to RGB (DetrImageProcessor expects RGB format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using the processor\n",
    "    inputs = processor(images=frame_rgb, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Convert outputs (bounding boxes and class logits) to COCO API format\n",
    "    # Let's only keep detections with score > 0.3\n",
    "    target_sizes = torch.tensor([frame.shape[:2]])\n",
    "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.3)[0]\n",
    "\n",
    "    # Iterate over the results and draw bounding boxes and labels using OpenCV\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "\n",
    "        # Draw the bounding box\n",
    "        box = [int(b) for b in box]  # Convert to integers for drawing\n",
    "        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), 1)  # Red rectangle\n",
    "\n",
    "        # Draw the label\n",
    "        label_text = f\"{model.config.id2label[label.item()]}: {round(score.item(), 3)}\"\n",
    "        label_size = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n",
    "        label_bottom_left = (box[0], box[1] - 5)  # Adjust label position\n",
    "        label_top_right = (label_bottom_left[0] + label_size[0], label_bottom_left[1] - label_size[1])\n",
    "        cv2.rectangle(frame, label_bottom_left, label_top_right, (0, 0, 255), cv2.FILLED)  # Red filled rectangle\n",
    "        cv2.putText(frame, label_text, (box[0], box[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b782ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
